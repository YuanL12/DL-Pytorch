{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor in Pytorch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from IPython import display\n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "a = torch.randn(2, 3, requires_grad=False)\n",
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.8097, -0.0086,  0.4703],\n",
       "        [ 0.4996,  1.4457,  0.3959]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "b = torch.zeros_like(a)\n",
    "b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "torch.ones_like(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "c = torch.tensor(np.array([[1,2],[3,4]]))\n",
    "c"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maximum"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def relu(X):\n",
    "    #Return a tensor with the same shape with maximum value on each position\n",
    "    a = torch.zeros_like(X)\n",
    "    return torch.max(X, a) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "a, relu(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-0.8097, -0.0086,  0.4703],\n",
       "         [ 0.4996,  1.4457,  0.3959]]),\n",
       " tensor([[0.0000, 0.0000, 0.4703],\n",
       "         [0.4996, 1.4457, 0.3959]]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sum"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "a, a.sum(1, keepdim= True) # sum on each row and keep dimension"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-0.8097, -0.0086,  0.4703],\n",
       "         [ 0.4996,  1.4457,  0.3959]]),\n",
       " tensor([[-0.3479],\n",
       "         [ 2.3411]]))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "a.sum(1, keepdim= False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.3479,  2.3411])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Broadcasting Rule\n",
    "A general introduction is here:\n",
    "https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def softmax(X):\n",
    "    '''\n",
    "    Define the softmax function for a matrix\n",
    "    The division is row-wise.\n",
    "    '''\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition  # The broadcasting mechanism is applied here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "c, c.sum(1, keepdim=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[3],\n",
       "         [7]]))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(2,2) / (2,1) = (2,2)\n",
    "\n",
    "Since (2,1), (dimensions with size 1), will be stretched or “copied” to match the other, which is (2,2),\n",
    "```\n",
    "c.sum(1, keepdim=True) \n",
    "```\n",
    "becomes\n",
    "```\n",
    "tensor([[3,3], [7,7]])\n",
    "```\n",
    "In other words, Size 2 tensor will expand row-wise."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "c / c.sum(1, keepdim=True) # Division is for each row"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.6667],\n",
       "        [0.4286, 0.5714]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### If we do not keep dimension after summand"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "c.sum(1, keepdim=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([3, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "c.sum(1, keepdim=False).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "c / c.sum(1, keepdim=False) # Division is for each column"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.2857],\n",
       "        [1.0000, 0.5714]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(2,2) / (2,) = (2,2)\n",
    "\n",
    "Since (2,), (dimensions with size 1), will be stretched or “copied” to match the other, which is (2,2),\n",
    "\n",
    "```\n",
    "c.sum(1, keepdim=True) \n",
    "```\n",
    "becomes\n",
    "```\n",
    "tensor([[3., 7.], [3., 7.]])\n",
    "```\n",
    ". In other words, size 1 tensor will expand downward and keep the first element same as before"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multiplication\n",
    "Check shape and data type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "a.shape, b.shape, c.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]), torch.Size([2, 2]))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "a.dtype"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert data type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "c = c.to(a.dtype)\n",
    "c"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "a.T @ c "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.6890, 0.3789],\n",
       "        [4.3284, 5.7654],\n",
       "        [1.6579, 2.5241]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "d = torch.tensor([1,1])\n",
    "d.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "a.T @ c + d # broadcasting rule: expand on each row to the following rows"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.6890, 1.3789],\n",
       "        [5.3284, 6.7654],\n",
       "        [2.6579, 3.5241]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}